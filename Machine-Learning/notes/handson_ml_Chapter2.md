# **性能选择指标**
回归问题的典型性能选择指标是**均方根误差（RMSE）**，它表示预测值和观测值之间差异（称为残差）的样本标准差。做非线性拟合时,RMSE越小越好。
#### 均方根误差（RMSE）公式：
$$\operatorname{RMSE}(\boldsymbol{X}, h)=\sqrt{\frac{1}{m} \sum_{i=1}^{m}\left(h\left(\boldsymbol{x}^{(i)}\right)-y^{(i)}\right)^{2}}$$
其中：
* $m$ 是要在其上测量RMSE的数据集中的实例数，即训练样本数
* $x^{(i)}$ 是数据集中第i个实例的所有特征值（不含标签）的向量，而$y^{(i)}$是其标签（该实例的期望输出值）。例如第一个区域位于经度-118.29°，纬度33.91°，居民1416人，收入中位数为38372美元，房屋价值中位数为156400美元（忽略其他特征），那么：
$$\boldsymbol{x}^{(1)}=\left(\begin{array}{c}
-118.29 \\
33.91 \\
1416 \\
38372
\end{array}\right)$$
$$y^{(1)}=156400$$
* $x$ 是一个矩阵，其中包含数据集中所有实例的所有特征值（不包括标签）。每个实例只有一行，第 $i$ 行等于 $x^{(i)}$ 的转置，记为 $\left(x^{(i)}\right)^{T}$ 。例如，如果第一个区域数据如上，则矩阵 $X$ 如下：
$$\boldsymbol{X}=\left(\begin{array}{c}
\left(\boldsymbol{x}^{(1)}\right)^{\mathrm{T}} \\
\left(\boldsymbol{x}^{(2)}\right)^{\mathrm{T}} \\
\vdots \\
\left(\boldsymbol{x}^{(1999)}\right)^{\mathrm{T}} \\
\left(\boldsymbol{x}^{(2000)}\right)^{\mathrm{T}}
\end{array}\right)=\left(\begin{array}{cccc}
-118.29 & 33.91 & 1416 & 38372 \\
\vdots & \vdots & \vdots & \vdots
\end{array}\right)$$
* $h$ 是系统的预测函数，也称为假设。当给系统输入一个实例的特征向量 $x^{(i)}$ 时，他会为该实例输出一个预测值 $\hat{y}^{(i)}=h\left(\boldsymbol{x}^{(i)}\right)$。例如如果系统预测第一个区域的房价中位数为158400美元，则 $\hat{y}^{(i)}=h\left(\boldsymbol{x}^{(i)}\right)=158400$ 。该区域的预测误差为 $\hat{y}^{(1)}-y^{(1)}=2000$。
* $\operatorname{RMSE}(X, h)$ 时使用假设 $h$ 在一组实例中测量的成本函数。
**注明**：小写斜体字体表示标量值（如 $m$ 和 $y^{(i)}$ )和函数名称 $h$ ，将小写粗斜体字体用于向量（如 $\boldsymbol{x}^{(i)}$ ），将大学粗体字体用于表示矩阵（如 $\boldsymbol{X}$ ）
---
**平均绝对误差（MAE）** 也称为绝对平均偏差，同样也是衡量回归任务中的重要性能指标，它表示预测值和观测值之间绝对误差的平均值。
#### 平均绝对误差（MAE）：
$$\operatorname{MAE}(\boldsymbol{X}, h)=\frac{1}{m} \sum_{i=1}^{m}\left|h\left(\boldsymbol{x}^{(i)}\right)-y^{(i)}\right|$$
均方根误差（RMSE）和平均绝对误差（MAE）都是测量两个向量（预测值向量和目标值向量）之间距离的方法。其中他们有如下区别：
* 均方根误差（RMSE）是计算平方和的根与欧几里得范数相对应：这是计算距离的概念，它也称为 $\ell_{2}$ 范数，记作 $\| \cdot||_{2}$ 或 $\| \cdot||$ 。
* 平均绝对误差（MAE）是计算绝对值之和，对应于 $\ell_{1}$ 范数，记作 $\| \cdot||_{1}$ 。有时将其称为曼哈顿范数。
* 一般而言，包含n个元素的向量 $V$ 的 $\ell_{k}$ 范数定义为 $\|\boldsymbol{v}\|_{k}=\left(\left|v_{0}\right|^{k}+\left|v_{1}\right|^{k}+\cdots+\left|v_{n}\right|^{k}\right)^{1 / k}$ 。$\ell_{0}$ 给出了向量中的非零元素数量，$\ell_{\infty}$ 给出了向量中的最大绝对值。
* MAE是一种线性分数，所有个体差异在平均值上的权重都相等，比如，10和0之间的绝对误差是5和0之间绝对误差的两倍。但这对于RMSE而言不一样，后续的例子将进一步详细讨论。MAE很容易理解，因为它就是对残差直接计算平均，而RMSE相比MAE，会对高的差异惩罚更多。
---
#### 具体例子
案例1：真实值= [2,4,6,8]，预测值= [4,6,8,10]  
案例2：真实值= [2,4,6,8]，预测值= [4,6,8,12]  
案例1的MAE = 2.0，RMSE = 2.0 
案例2的MAE = 2.5，RMSE = 2.65
从上述例子中，我们可以发现RMSE比MAE更加多地惩罚了最后一项预测值。通常，RMSE要大于或等于MAE。等于MAE的唯一情况是所有残差都**相等或都为零**，如案例1中所有的预测值与真实值之间的残差皆为2，那么MAE和RMSE值就相等。

---
# 机器学习通用流程

**1. 安装CUDA和Tensorflow, Sk-learning**
按照网上通用教程进行安装，一般问题不多。
需要注意的是：
	* 在本机NVIDIA控制面板下查看nvcuda.dll的属性时是cuda 11.6.99驱动，但是官网下载11.6的版本一直安装不上，安装11.5却可以安装成功，这里建议安装11.5的版本，尽量避免出现一些疑难杂症。
	* 安装tensorflow成功之后，在conda命令界面强烈建议使用pip进行包管理，之前博主使用conda install命令安装matplotlib时，出现了依赖的包的版本要求不一致的情况导致matplotlib一直安装不上，后使用pip一次即正确安装好可以使用。

**2. 配置机器学习虚拟环境及所需要的依赖包**
书中本章采用Jupyter notebook来进行演示，好处是轻量且直观。但博主自己有rtx显卡的笔记本，所以正好借此机会安装cuda，所以就使用了pycharm的pro版本（学生免费）来进行实验。
配置环境的部分不在赘述，强烈建议使用anaconda3来管理，新建一个虚拟环境，在conda界面中使用pip安装必要的依赖包，然后在ide中自由切换虚拟环境，非常方便。
**3. 下载数据**
不同目的的机器学习的数据来源是不一样的，书中是写了一个函数自动从github网站上在相应目录下自动获取csv文件，这里我整个fork了handson-ml2的这个仓库并且同步到了本地，所以我直接把
 
**4. 检查数据**



**5. 创建测试集**